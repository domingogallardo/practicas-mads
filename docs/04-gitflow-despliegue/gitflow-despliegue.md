
# Pr谩ctica 4: Trabajo en equipo con GitFlow y despliegue en producci贸n

## 1. Objetivos y resumen de la pr谩ctica ##

En esta pr谩ctica se pretende conseguir:

1. Crear los equipos de trabajo en GitHub.
2. Adaptar el flujo de trabajo en Git y GitHub al trabajo en equipo.
3. Desplegar la aplicaci贸n usando una base de datos de producci贸n y
   mantener esta base de datos.
4. Implementar GitFlow:
    - Desarrollar nuevas features con GitFlow.
    - Lanzamiento de una versi贸n nueva usando GitFlow.

## 2. Formaci贸n de equipos ##

En esta pr谩ctica comenzamos a trabajar en equipos de 3 personas.

Cada equipo trabajar谩 con un repositorio com煤n seleccionado de uno de
los miembros del equipo. Utilizaremos _GitHub Classroom_ para crear el
_team_ y el repositorio.

### Pasos a seguir ###

- Deb茅is formar equipos de **3 personas**. Enviad los componentes al
  foro de Moodle y os asignar茅 un nombre de equipo. Utilizad despu茅s
  el enlace de GitHub Classroom que enviar茅 al foro de Moodle para
  crear el equipo y apuntaros a 茅l.
  
    El primero que use el enlace debe crear el repositorio,
    escribiendo el nombre del equipo, como se muestra en la siguiente
    imagen.

    <img src="imagenes/nombre-repo-github-classroom.png" width="600px"/>

    El equipo trabajar谩 con un repositorio creado por GitHub Classroom
    con el nombre `todolist--NOMBRE-EQUIPO`. Al igual que en
    la pr谩ctica 2, el repositorio se crear谩 en la organizaci贸n `mads-ua-21-22`.

    <img src="imagenes/repo-creado-github-classroom.png" width="700px"/>

    Una vez que la primera persona ha creado el equipo y el
    repositorio, las siguientes personas que usan el enlace pueden
    unirse al equipo creado o crear un nuevo equipo:
    
    <img src="imagenes/unirse-repo-github-classroom.png" width="700px"/>

- Una vez creado el repositorio deb茅is crear en 茅l un tablero para
  gestionar las tarjetas con los _issues_ y los pull
  requests. Creadlos con las mismas columnas que en las pr谩cticas 2 y 3.

- Escoged el proyecto que vais a usar como punto de partida de estas
  dos 煤ltimas pr谩cticas de entre los proyectos de los miembros del
  equipo. Intentad que se un proyecto con c贸digo limpio y f谩cilmente
  ampliable.

    Subidlo al nuevo repositorio, cambiando la URL del `origin` del
    repositorio local y haciendo un push:

    ```
    $ git remote set-url origin https://github.com/mads-ua-21-22/todolist-NOMBRE-EQUIPO.git
    $ git push -u origin main
    ```
    Por 煤ltimo, los otros miembros del equipo deber谩n clonar el
    repositorio para que los tres pod谩is trabajar con 茅l en local.

- Cambiad el nombre del proyecto (en el fichero `POM.xml` y en el
  `about.html` a `todolist-equipo-XX`.

    Haced un commit directamente en `main` con estos
    cambios. Comprobad que GitHub Actions sigue funcionando
    correctamente. 

## 3. Nuevo flujo de trabajo para los _issues_ ##

Debemos adaptar el flujo de trabajo en GitHub al trabajo en equipo. En
cuanto a la gesti贸n de los _issues_ y tablero del proyecto cambiaremos
lo siguiente:

- **Selecci贸n del _issue_**: Al pasar un _issue_ de `To do`a `In
  progress` se debe asignar un responsable del desarrollo del _issue_.
- **Nueva rama con el _issue_**: El responsable seleccionado ser谩 el que abra una
  rama nueva para el desarrollo del ticket y la subir谩 a
  GitHub.
- **Desarrollo**: Se trabaja en la rama. Cualquier compa帽ero puede
  unirse al ticket y trabajar junto con el responsable, trabajando
  sobre la rama.
- **Pull request**: Cuando el ticket se ha terminado, el responsable
  abre un pull request en GitHub y pone la tarjeta en la columna
  `In pull request`.
- **Revisi贸n de c贸digo**: Los miembros del equipo revisan el c贸digo en
  el pull request (consultar documentaci贸n en GitHub: [Reviewing
  proposed changes in a pull
  request](https://help.github.com/articles/reviewing-proposed-changes-in-a-pull-request/)). Al
  menos uno de los miembros del equipo deben dar el OK, a帽adiendo una
  reacci贸n. Deb茅is configurar la opci贸n de GitHub que obliga a que
  haya un [m铆nimo de revisores](https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/enabling-required-reviews-for-pull-requests) en el pull request.
- **Integraci贸n del pull request**: Cuando un miembro da el OK, el
  responsable de la tarea integra el pull request.

Para implementar el trabajo en equipo ser谩 necesario trabajar sobre
ramas remotas compartidas. A continuaci贸n explicamos con m谩s detalle
algunos aspectos comandos de Git necesarios.

### Comandos Git ###

Veamos algunos comandos de Git relacionados con el trabajo compartido
en repositorios y ramas remotas.

- Subir una rama al repositorio remoto:

    ```
    $ git checkout -b nueva-rama
    $ git push -u origin nueva-rama
    ```

- Descargar por primera vez una rama del repositorio remoto y moverse
  a ella

    ```
    $ git fetch
    $ git checkout nueva-rama 
    ```

    El comando `git fetch` se descarga todos los cambios pero no los
    mezcla con las ramas locales. Los deja en ramas locales conectadas
    con las remotas (ramas _remote tracking_) a las que les da el
    nombre del servidor y la rama (`origin/nueva-rama`). Estas ramas
    _remote tracking_ son de solo lectura y no podemos hacer commits
    en ellas. Para trabajar con ellas hay que crear una rama local
    conectada a ella (normalmente tendr谩 el mismo nombre, por ejemplo
    `nueva-rama`). 

    En el caso del comando anterior, el comando
    
    ```
    $ git checkout nueva-rama
    ```
    
    es equivalente a 
    
    ```
    $ git checkout -b nueva-rama origin/nueva-rama
    ```
    
    Se est谩 creando una rama local `nueva-rama` conectada a la rama
    `origin/nueva-rama`.

- Actualizar una rama con cambios que otros compa帽eros han subido al
  repositorio remoto:

    ```
    $ git checkout nueva-rama
    $ git pull
    ```

    El comando `git pull` es equivalente a un `git fetch` seguido de
    un `git merge`. El comando `git fetch` actualiza la rama local
    conectada con la _remote tracking_ `origin/nueva-rama`. El comando `git pull`
    es equivalente a hacer:

    ```
    $ git checkout nueva-rama
    $ git fetch
    $ git merge origin/nueva-rama
    ```

- Subir cambios de la rama actual:

    ```
    (estando en la rama que queremos subir)
    $ git push
    ```

    Si somos nosotros los que hemos creado la rama, hay que
    configurarla para que funcione correctamente el `git push`
    haciendo:
    
    ```
    $ git push -u origin nueva-rama
    ```
        
- Comprobar el estado de las ramas locales:

    ```
    $ git branch -vv
    ```

    Con la opci贸n `-a` (`git branch -vva`) se muestra tambi茅n el
    estado de las ramas _remote tracking_ de solo lectura (en rojo, y
    precedidas con el nombre `remotes/`):
    
    ```
    $  git branch -vva
      main                  dd867ac [origin/main] Colocados esquemas en su directorio
    * prueba                8d2d093 [origin/prueba] Correcci贸n
      remotes/origin/HEAD   -> origin/main
      remotes/origin/main   dd867ac Colocados esquemas en su directorio
      remotes/origin/prueba 8d2d093 Correcci贸n
    ```
    
    Este comando no accede directamente al servidor, sino que muestra
    la informaci贸n de la 煤ltima vez que se accedi贸 a 茅l. Si queremos
    la informaci贸n actualizada podemos hacer un `git fetch --all`
    antes:

    ```
    $ git fetch --all
    $ git branch -vva
    ```

    Es importante recordar que `git fetch` (a diferencia de `git
    pull`) no modifica los repositorios locales, sino que actualiza
    las ramas _remote tracking_.

- Informaci贸n de los repositorios remotos:

    ```
    $ git remote show origin
    ```

    Proporciona informaci贸n del repositorio remoto, todas sus ramas,
    del local y de la conexi贸n entre ambos.

    ```
    $ git remote -v update
    ```

    Proporciona informaci贸n del estado de las ramas remotas y locales
    (si est谩n actualizadas o hay cambios en algunas no bajadas o
    subidas).

- Borrado de ramas remotas desde el terminal:

    ```
    $ git push origin --delete nueva-rama
    $ git remote prune origin
    ```

- Si necesitamos en la rama de _feature_ c贸digo que se haya a帽adido en
  la rama `main`.
  
    Podemos hacer un _merge_ de la rama `main` en la rama de
    _feature_ para incorporar los avances de c贸digo que se han hecho
    en `main` y que necesitamos en nuestra nueva rama:
    
    ```
    $ git checkout nueva-rama
    $ git merge main
    ```


- Soluci贸n de conflictos en un _pull request_:

    Recordamos lo que hemos visto en teor铆a sobre la soluci贸n de
    conflictos detectados en un _pull request_.
    
    Supongamos que hay un conflicto entre la nueva rama y
    `main`. GitHub detectar谩 el conflicto en la p谩gina de _pull
    request_. Para arreglar el conflicto:
    
    ```
    $ git checkout main
    $ git pull
    $ git checkout nueva-rama
    $ git merge main
    # arreglar el conflicto
    $ git push
    # ya se puede hacer el merge en GitHub
    ```
    
### Pasos a seguir ###

1. A帽adid el milestone 1.3.0 y etiquetad todos los pr贸ximos issues con
  茅l. Probad el nuevo flujo de trabajo descrito anteriormente creando
  un nuevo _issue_ denominado `Actualizar la p谩gina Acerca de`. En la
  descripci贸n de _issue_ comentad que se debe modificar la p谩gina para
  que muestren todos los miembros del equipo y el nuevo n煤mero de
  versi贸n de la aplicaci贸n (`1.3.0-SNAPSHOT`).

2. Escoged una persona del equipo como responsable del _issue_. El
  responsable del _issue_ ser谩 el responsable de integrarlo en
  `main` y de solucionar los conflictos que puedan surgir.

3. Probad los comandos Git anteriores en una rama en la que se
  resuelva el _issue_. Cada miembro del equipo deber谩 descargar esa
  rama y realizar un commit en el que se a帽ada su nombre a la lista de
  autores de la aplicaci贸n.

4. Cread el pull request en GitHub, poniendo como responsable del PR al
  mismo responsable del _issue_.

5. Provocad un conflicto y arregladlo. Para ello se debe a帽adir un
  commit en `main` que entre en conflicto con los cambios realizados
  en la rama. Despu茅s se arreglar谩 el conflicto y se subir谩 la
  soluci贸n al pull request.

6. Por 煤ltimo, revisad el c贸digo, aceptadlo e integrad el PR en
   _main_.


## 4. Contenedor con la aplicaci贸n ToDoList ##

Una de las cosas que vamos a hacer en esta pr谩ctica (en el siguiente
apartado) es poner en producci贸n en el servidor de la asignatura la
aplicaci贸n ToDoList conect谩ndola con la base de datos. En las
pr谩cticas 1 y 2 ya hemos construido el contenedor Docker de la
aplicaci贸n, con el siguiente fichero Dockerfile:

```docker
FROM openjdk:8-jdk-alpine
COPY target/*.jar app.jar
ENTRYPOINT ["java","-Djava.security.egd=file:/dev/urandom","-jar","/app.jar"]
```

Este Dockerfile tiene un problema importante. El comando de ejecuci贸n
es fijo y no permite definir ning煤n par谩metro de ejecuci贸n. No es
posible, por ejemplo, definir el perfil de Postgres, ni definir
ning煤n par谩metro de configuraci贸n.

Debemos cambiarlo de la siguiente forma:

```docker hl_lines="3"
FROM openjdk:8-jdk-alpine
COPY target/*.jar app.jar
ENTRYPOINT ["sh","-c","java -Djava.security.egd=file:/dev/urandom -jar /app.jar ${0} ${@}"]
```

De esta forma podremos llamar al comando docker a帽adiendo al final
par谩metros que se van a pasar al comando java. La forma de a帽adir
variables de entorno a ese comando java es precedi茅ndolos con dos
guiones `--`. Por ejemplo:

```
$ docker run --rm <usuario>/mads-todolist-equipoXX --spring.profiles.active=postgres --POSTGRES_HOST=host-prueba 
```

Vamos a probarlo, creando y subiendo la nueva imagen a
DockerHub y despleg谩ndola en el servidor de la asignatura.

### Pasos a seguir ###

Deb茅is hacer lo siguiente:

1. Creamos un issue llamado `Configuraci贸n imagen docker` y
   trabajamos en la rama `imagen-docker`.

2. Cambiad el fichero Dockerfile de la aplicaci贸n tal y como se indica en el listado
   anterior:
   
    **Fichero `Dockerfile`**:

    ```docker
    FROM openjdk:8-jdk-alpine
    COPY target/*.jar app.jar
    ENTRYPOINT ["sh","-c","java -Djava.security.egd=file:/dev/urandom -jar /app.jar ${0} ${@}"]
    ```

3. Cread la nueva imagen Docker con el nombre
   `mads-todolist-equipoXX` y la etiqueta `1.3.0-snapshot`. El usuario puede ser cualquier miembro
   del equipo, no es necesario que sea el autor del proyecto original.
   
    ```
    $ ./mvnw package
    $ docker build -t <usuario-docker>/mads-todolist-equipoXX:1.3.0-snapshot . 
    ```

3. Probad que funcionan correctamente los par谩metros de configuraci贸n
   en la imagen Docker. Una forma sencilla de hacerlo es comprobar que
   se puede definir el perfil de Postgres y modificar alguno de sus
   par谩metros. Deber谩 aparecer un mensaje de error de que no se puede
   conectar con la base de datos (lo que est谩 bien, porque significa
   que s铆 que se ha cargado el perfil).
   
    ```
    $ docker run --rm <usuario>/mads-todolist-equipoXX:1.3.0-snapshot --spring.profiles.active=postgres --POSTGRES_HOST=host-prueba 
    ```

    <img src="imagenes/perfil-contenedor.png" width="700px" />
    <img src="imagenes/error-contenedor.png" width="700px" />

4. Subid, por 煤ltimo, la imagen a Docker Hub y cerrad el PR y el issue.
   
    ````
    $ docker login
    $ docker push <usuario-docker>/mads-todolist-equipoXX:1.3.0-snapshot
    ````


## 5. Despliegue en producci贸n con BD ##

Vamos a ver c贸mo ejecutar en producci贸n el contenedor con la
aplicaci贸n de forma que se conecte con una base de datos postgres.

En las pr谩cticas 1 y 2 vimos c贸mo construir una versi贸n en forma de
contenedor de nuestra aplicaci贸n Spring Boot y en la pr谩ctica 3 vimos
como usar un contenedor de Postgres para definir un servicio de base
de datos con el que conectar la aplicaci贸n.

En esta pr谩ctica vamos a definir la configuraci贸n en producci贸n
definitiva de nuestra aplicaci贸n. Veremos c贸mo poner en marcha dos
contenedores y conectarlos entre si. En nuestro caso un contenedor
tendr谩 la base de datos postgres y el otro la aplicaci贸n Spring Boot.

<img src="imagenes/contenedores-produccion.png" width="600px"/>

La imagen anterior muestra los dos contenedores conectados por una
red. Desde el contenedor con la aplicaci贸n se acceder谩 a la direcci贸n
`postgres:5432` para conectarse con la base de datos. Veremos los
comandos de docker para definir una red y para lanzar el contenedor de
base de datos en esa direcci贸n de la red.

El contenedor de base de datos montar谩 el directorio actual del host
en el directorio `/mi-host` del contenedor. De esta forma, cualquier
fichero que coloquemos en ese directorio del contenedor ser谩 visible
en el directorio actual del host (y viceversa). Usaremos este
directorio para guardar datos de la base de datos, como copias de
seguridad o ficheros de migraci贸n.

El contenedor de base de datos implementar谩 la base de datos en
producci贸n. 

!!! Note "Base de datos de producci贸n"
    La base de datos de producci贸n es la que mantiene los datos
    introducidos por los usuarios de la misma. Hay que prestar una
    atenci贸n especial a esta base de datos y definir pol铆ticas de
    respaldo y de control de cambios para evitar que se produzca
    cualquier p茅rdida de informaci贸n. Veremos que una
    de las cuestiones que hay que asegurar es que la aplicaci贸n no
    puede modificar el esquema de datos de esta base de datos. 
    
    Habr谩 que definir tambi茅n un flujo de trabajo para actualizar la base de
    datos de producci贸n con los cambios del modelo de datos
    introducidos por la nuevas funcionalidades (nuevas tablas y nuevas
    relaciones).

### Pasos a seguir ###

Veamos paso a paso c贸mo crear la configuraci贸n anterior. En muchos
casos tendremos que usar el nombre de nuestro equipo. En los ejemplos
hemos usado `equipo01`. Deb茅is cambiarlo por el nombre de vuestro equipo.

1. Nos conectamos al servidor de la asignatura con uno de los usuarios
   del equipo. La direcci贸n IP est谩 en un mensaje enviado al foro de
   la asignatura.

    ```
    $ ssh alu02@<direccion-IP>
    ```

2. Creamos una red gestionada por Docker:

    ```
    $ docker network create network-equipo01
    ```

3. Lanzamos el contenedor con la base de datos usando la red creada
  anteriormente y con el nombre `db-equipo01`. Definimos el nombre del
  host creado en el contenedor como `postgres` con el modificador
  `--network-alias`.

    ```
    $ docker run -d --network network-equipo01 --network-alias postgres -v ${PWD}:/mi-host --name db-equipo01 -e POSTGRES_USER=mads -e POSTGRES_PASSWORD=mads -e POSTGRES_DB=mads postgres:13
    ```

    El modificador `-v` permite montar el directorio actual en el
    directorio `/mi-host` del contenedor. Vamos a probar que funciona
    correctamente. 

4. Nos conectamos al contenedor lanzando un `bash`
   interactivo. Estando en el contenedor creamos un fichero en el
   directorio `/mi-host`, salimos del contenedor y comprobamos que
   est谩 en el directorio actual

    ```
    $ docker exec -it db-equipo01 bash
    root@e470db191dc6:/# cd /mi-host
    root@e470db191dc6:/mi-host# echo "Hola" > prueba.txt
    root@e470db191dc6:/mi-host# exit
    $ ls
    prueba.txt
    $ more prueba.txt
    Hola
    ```

5. Con esto ya tenemos configurado y en marcha el contenedor con la
   base de datos Postgres. Esta va a ser nuestra base de datos de
   producci贸n. Vamos ahora a poner en marcha la aplicaci贸n.

    Descargamos la 煤ltima versi贸n de nuestra aplicaci贸n y lanzamos el
    contenedor usando la red definida anteriormente. Los modificadores
    `--spring.profiles.active` y `--POSTGRES_HOST` permiten pasar al
    contenedor esas variables del entorno.

    ```
    $ docker pull <usuario>/mads-todolist-equipo01:1.3.0-snapshot
    $ docker run --rm --name spring-boot-equipo01 --network network-equipo01 -p8080:8080 <usuario>/mads-todolist-equipo01:1.3.0-snapshot --spring.profiles.active=postgres --POSTGRES_HOST=postgres
    ```

    隆隆隆Enhorabuena!!! 隆Ya tenemos la aplicaci贸n en producci贸n
    trabajando con la base de datos!

    Podremos conectarnos a la aplicaci贸n usando la direcci贸n IP del
    servidor de la asignatura y el puerto 8080.

    Probamos la aplicaci贸n y creamos alg煤n usuario de prueba. Por 煤ltimo
    paramos el contenedor y lo volvemos a arrancar para comprobar que los
    datos son persistentes.

6. Para comprobar que la base de datos est谩 funcionando correctamente
   podemos conectarnos al contenedor y examinar la base de datos
   `mads` y alguna de sus tablas:

    ```
    $ docker exec -it db-equipo01 bash
    # psql -U mads -W mads (nos pedir谩 la contrase帽a: mads)
    # \l (lista las bases de datos)
    # \dt (lista las tablas)
    # SELECT * FROM usuarios;
    ```

    La base de datos se mantendr谩 mientras que no borremos el
    contenedor. Podemos pararlo y volver a ponerlo en marcha y seguiremos
    conservando los datos:

    ```
    $ docker stop db-equipo01
    $ docker start db-equipo01
    ```

## 6. Perfil de producci贸n y mantenimiento de la base de datos de producci贸n ##

### Perfil de producci贸n ###

Una vez que vamos a trabajar en producci贸n con una base de datos, esta
base de datos ser谩 un elemento clave de la aplicaci贸n. No debemos,
bajo ning煤n concepto, perder datos que se hayan introducido en ella,
ya que son datos de nuestros usuarios y clientes.

Es imprescindible para ello cambiar el modo con el que la aplicaci贸n
construye las tablas de la base de datos. Sabemos que nuestra
aplicaci贸n est谩 trabajando con JPA/Hibernate y que las tablas de la
base de datos se construyen de forma autom谩tica. Si hay alg煤n cambio
en las entidades (se a帽ade alg煤n atributo o alguna nueva entidad)
Spring Boot actualiza las tablas de la base de datos de forma
autom谩tica cuando se lanza la aplicaci贸n. Esto es razonable si estamos
trabajando en un entorno de desarrollo, pero est谩 **totalmente
desaconsejado** en un entorno de producci贸n.

El par谩metro `spring.jpa.hibernate.ddl-auto` es el que determina el
funcionamiento de la actualizaci贸n de las tablas de la base de
datos. Su valor puede ser:

- `CREATE`: El esquema de datos se crea de nuevo cada vez que se lanza
  la aplicaci贸n. Una vez creado, se a帽aden los datos definidos en el
  fichero `spring.datasource.data` si el
  `spring.datasource.initialization-mode` tiene como valor
  `always`. Esta es la forma de funcionar de los tests.

- `UPDATE`: El esquema de datos de la base de datos se actualiza
  autom谩ticamente cuando hay un cambio en las entidades de la
  aplicaci贸n. As铆 es como tenemos configurado el perfil por defecto de
  nuestra aplicaci贸n. Si estamos trabajando con la base de datos
  Postgres, se actualizar谩 el esquema de datos. Pero esto no es
  recomendable para producci贸n, porque no tenemos control de las
  instrucciones de actualizaci贸n y pueden resultar en alguna p茅rdida
  de datos.

- `VALIDATE`: El esquema de datos de la base de datos se valida con
  respecto al esquema de datos definido por las entidades JPA. Si hay
  alguna diferencia, salta una excepci贸n. Este es el valor que hay que
  usar cuando lanzamos la aplicaci贸n en producci贸n.
  
Vamos a definir en la aplicaci贸n un nuevo perfil de ejecuci贸n, llamado
`postgres-prod`, en el que pondremos el valor del par谩metro
`spring.jpa.hibernate.ddl-auto` a `VALIDATE`. Y ser谩 este el perfil
que usaremos para lanzar la aplicaci贸n en el servidor de producci贸n.


### Mantenimiento de la base de datos de producci贸n ###

En una aplicaci贸n en producci贸n se deben configurar pol铆ticas
estrictas de realizaci贸n de copias de seguridad y de integridad de los
datos. Tambi茅n en la gesti贸n de las versiones y en la actualizaci贸n
del esquema de datos. 

Esto 煤ltimo se denomina una _migraci贸n_ de la base de datos y
representa un elemento fundamental del mantenimiento en producci贸n de
una aplicaci贸n, sobre todo cuando estamos trabajando de una forma 谩gil
e incremental. Es un tema avanzado muy importante, pero que no podemos
abordar en la asignatura por falta de tiempo. Un par de referencias
que os pueden ser de utilidad son el art铆culo [Evolutionary Database
Design](https://martinfowler.com/articles/evodb.html) y herramientas
como
[Flyway](https://www.baeldung.com/database-migrations-with-flyway) que
permiten automatizar las migraciones de la base de datos.

En la pr谩ctica vamos a trabajar con la base de datos de producci贸n de
dos formas:

1. Realizaremos una copia de seguridad antes de instalar una nueva
   versi贸n.
2. Actualizaremos el esquema de datos aplicando un fichero de
   migraci贸n que construiremos manualmente.

#### Copias de seguridad ####


Si eliminamos el contenedor con la base de datos se perder谩n todos los
datos. Para evitar perder los datos, con el contenedor en marcha
podemos hacer una copia de seguridad de la base de datos `mads` en el
directorio compartido:

```
$ docker exec -it db-equipo01 bash
# pg_dump -U mads --clean mads > /mi-host/backup03092021.sql
```

La copia de seguridad se guarda en el directorio compartido. Podemos
poner la fecha en el nombre del fichero. Por ejemplo, la copia
anterior ha sido creada el 3 de septiembre del 2021.

Para restaurar una copia de seguridad basta con ejecutar el fichero
SQL en la base de datos:

```
$ docker exec -it db-equipo01 bash
# psql -U mads mads < /mi-host/backup03092021.sql
# exit
```

#### Migraci贸n de la base de datos ####

Podemos obtener el esquema de datos de la aplicaci贸n (la definici贸n de
las tablas, sin los datos) conect谩ndonos al contenedor y ejecutando el
siguiente comando para guardar el fichero en el directorio compartido:

```
$ docker exec -it db-equipo01 bash
# pg_dump -U mads -s mads > /mi-host/schema.sql
# exit
```

Tendremos el esquema de datos en el directorio actual, que hemos
montado en el contenedor con la instrucci贸n -V.

Los esquemas son instrucciones SQL en texto plano. Supongamos que
tenemos una nueva versi贸n de la aplicaci贸n (`1.3.0`) en la que hemos
a帽adido el atributo `descripcion` a la entidad `Equipo`.

Si generamos el esquema de datos de esta nueva versi贸n y lo llamamos
`schema-1.3.0.sql` lo podemos comparar con el esquema anterior usando
el comando de linux `diff`:

```
% diff sql/schema-1.3.0.sql sql/schema-1.2.0.sql 
41,42c41
<     nombre character varying(255),
<     descripcion character varying(255)
---
>     nombre character varying(255)
```

Por ejemplo, en el ejemplo mostrado, el fichero `schema-1.3.0.sql` tiene un
campo adicional que el fichero `schema-1.2.0.sql`. Se trata del
campo `descripcion`. En la versi贸n anterior (`schema-1.2.0.sql`) la
tabla `equipo` se define como:

```sql
CREATE TABLE public.equipos (
    id bigint NOT NULL,
    nombre character varying(255)
);
```

Mientras que en la versi贸n nueva (`schema-1.3.0.sql`) se define como:

```sql
CREATE TABLE public.equipos (
    id bigint NOT NULL,
    nombre character varying(255),
    descripcion character varying(255)
);
```

Si queremos migrar la base de datos de producci贸n de una versi贸n a
otra, debemos crear un script de migraci贸n en el que modifiquemos
煤nicamente el esquema de datos anterior para adaptarlo al nuevo.

En este caso el script lo llamaremos `schema-1.2.0-1.3.0.sql` y
contendr谩 煤nicamente la siguiente instrucci贸n:

```sql
ALTER TABLE public.equipos
ADD COLUMN descripcion character varying(255)
```

Para actualizar la base de datos de producci贸n s贸lo tenemos que
ejecutar el script anterior:

```
$ docker exec -it db-equipo01 bash
$ psql -U mads mads < /mi-host/schema-1.2.0-1.3.0.sql
ALTER TABLE
$ exit
```

De esta forma habremos a帽adido manualmente un campo en la tabla
`equipos`.

La aplicaci贸n deber谩 funcionar ahora perfectamente si la lanzamos en
modo producci贸n, definiendo la variable que hemos mencionado antes con
el modo `validate`:

```
spring.jpa.hibernate.ddl-auto=validate
```

### Pasos a seguir ###

1. Creamos un issue llamado `Esquema de datos y perfil de producci贸n` y trabajamos
   en la rama `esquema-datos` y en el pull request equivalente.
   
    ```
    $ git checkout -b esquema-datos
    $ git push -u origin esquema-datos
    ```

2. Lanzamos la aplicaci贸n en local con el modo `postgres`, trabajando
   sobre la base de datos. Previamente hemos lanzado el contenedor postgres
   montando el directorio actual en su directorio `/mi-host/`:
   
    ```
    $ docker run -d -p 5432:5432 -v ${PWD}:/mi-host --name postgres-develop -e POSTGRES_USER=mads -e POSTGRES_PASSWORD=mads -e POSTGRES_DB=mads postgres:13
    $ ./mvnw spring-boot:run -D profiles=postgres
    ```

3. Al lanzar la aplicaci贸n se habr谩 creado en la base de datos el
   esquema de datos. Lo generamos y lo salvamos en el directorio
   actual:
   
    ```
    $ docker exec -it postgres-develop bash
    # pg_dump -U mads -s mads > /mi-host/schema-1.2.0.sql
    # exit
    ```
   
4. Comprobamos que el esquema de datos se ha creado correctamente y lo
   movemos al directorio `sql` en el directorio ra铆z:
   
    ```
    $ ls -l
    Dockerfile
    README.md
    mvnw
    mvnw.cmd
    pom.xml
    schema-1.2.0.sql
    src
    target
    $ mkdir sql
    $ mv schema-1.2.0.sql sql
    ```

5. Creamos un commit con el nuevo fichero con el esquema de datos.

6. Creamos un nuevo fichero con el perfil de producci贸n:

    **Fichero `/src/main/resources/application-postgres-prod.properties`**:
    
    ```
    POSTGRES_HOST=localhost
    POSTGRES_PORT=5432
    DB_USER=mads
    DB_PASSWD=mads
    spring.datasource.url=jdbc:postgresql://${POSTGRES_HOST}:${POSTGRES_PORT}/mads
    spring.datasource.username=${DB_USER}
    spring.datasource.password=${DB_PASSWD}
    spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.PostgreSQL9Dialect
    spring.datasource.initialization-mode=never
    spring.jpa.hibernate.ddl-auto=validate
    ```
    
    Contiene exactamente la misma configuraci贸n del perfil postgres,
    excepto la propiedad `spring.jpa.hibernate.ddl-auto` que tiene el
    valor `validate`.

7. Probamos en local que el perfil funciona correctamente, lanz谩ndolo:

    ```
    $ ./mvnw spring-boot:run -D profiles=postgres-prod
    ```

    Probamos que realmente valida el esquema de datos, en lugar de
    actualizarlo. Para ello, paramos y borramos el contenedor postgres
    y lo lanzamos de nuevo. Esto crear谩 una base de datos vac铆a:
    
    ```
    $ docker container stop docker-develop
    $ docker container rm docker-develop
    $ docker run -d -p 5432:5432 -v ${PWD}:/mi-host --name postgres-develop -e POSTGRES_USER=mads -e POSTGRES_PASSWORD=mads -e POSTGRES_DB=mads postgres:13
    ```
    
    Si ahora lanzamos la aplicaci贸n en modo `postgres-prod`
    obtendremos un error:
    
    ```
    $ ./mvnw spring-boot:run -D profiles=postgres-prod
    org.springframework.beans.factory.BeanCreationException: Error
    creating bean with name 'entityManagerFactory' defined in class
    path resource  [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaConfiguration.class]: 
    Invocation of init method failed; nested exception is
    javax.persistence.PersistenceException: [PersistenceUnit: default]
    Unable to build Hibernate SessionFactory; nested exception is 
    org.hibernate.tool.schema.spi.SchemaManagementException: 
    Schema-validation: missing table [equipo_usuario]
    ```
    
8. Si queremos volver a construir la base de datos, no tenemos m谩s que
   lanzar la aplicaci贸n con el perfile `postgres`, que tiene la
   propiedad `spring.jpa.hibernate.ddl-auto` con el valor
   `update`.

9. Hacemos un commit con el nuevo perfil, subimos los cambios y
   cerramos el pull request y el issue.

10. Nos conectamos al servidor de la asignatura y ponemos en marcha la
    base de datos de producci贸n y hacemos una copia de seguridad tal y
    como se explica anteriormente. Dejamos el fichero en el servidor
    de la asignatura, indicando la fecha en el nombre del mismo. Por
    ejemplo `backup10112021.sql`.


## 7. Desarrollo de la nueva versi贸n con GitFlow ##

El flujo de trabajo Git que vamos a seguir es muy similar al flujo de
trabajo GitFlow (recordad la [clase de
teor铆a](https://github.com/domingogallardo/apuntes-mads/blob/main/apuntes/08-git-workflows/git-workflow.md#gitflow))

### Ramas de largo recorrido ###

En GitFlow se publican las distintas versiones del proyecto en la rama
_long-lived_ `main` y se hace el desarrollo en la rama
`develop`. A partir de ahora no desarrollaremos directamente en
`main` sino en `develop`.

En la p谩gina de configuraci贸n del repositorio en GitHub en `Settings >
Branches > Default branch` se puede configurar la rama por defecto
contra la que se realizar谩n los commits y la que aparecer谩 en la
p谩gina del proyecto. Tendr茅is que definir `develop`.

### Ramas de feature ###

Desde el comienzo de trabajo con Git en las pr谩cticas 2 y 3 estamos
haciendo un desarrollo basado en ramas de corto recorrido,
equivalentes a las ramas de _features_ de GitFlow. 

Tal y como se comenta en GitFLow estas ramas saldr谩n de `develop` y se
integrar谩n en `develop`. La diferencia es que en GitFlow estas ramas
se integran con la rama de desarrollo manualmente haciendo `merge`,
mientras que nosotros las integramos haciendo un pull request.

### Pasos a seguir ###

1. Cread la rama **`develop`** y configurarla como rama principal del
  proyecto en GitHub. Todos los otros miembros deber谩n descargarla y
  moverse a ella en sus repositorios locales. Esta rama pasar谩 a ser
  la de desarrollo principal.

2. Cread tres _issues_ distintos, simulando tres nuevas
  funcionalidades. Deben ser issues sencillos, que no cuesten
  demasiado de implementar (mejorar alg煤n defecto de la aplicaci贸n,
  cambiar alg煤n elemento de alguna de las vistas, o algo
  similar). **Uno de los cambios debe afectar a alguna entidad**, por
  ejemplo a帽adir un campo de descripci贸n a los equipos y actualizar
  las vistas correspondientes para permitir su inicializaci贸n y su
  actualizaci贸n.

    Cada uno de los miembros del equipo ser谩 el responsable de
    uno de los issues.
  
3. Configurad el repositorio GitHub para obligar a que cualquier _pull
  request_ tenga que tener la revisi贸n de una persona distinta del
  responsable del PR.
  
4. Desarrollad e integrar los issues en `develop` siguiendo el flujo de
  trabajo planteado anteriormente. Deb茅is ir actualizando el tablero
  de GitHub se actualiza correctamente.

### Rama de release ###

Hasta ahora hemos hecho los _releases_ en la rama `main`. A partir
de ahora seguiremos la estrategia de GitFlow y haremos ramas de
_release_ que salen de `develop` y se integran en `main` y en
`develop`.

Haremos tambi茅n la integraci贸n haciendo pull request.

Una cosa importante que tendremos que hacer en el release es crear el
guardar el de datos de la nueva versi贸n y crear el script de migraci贸n
de la base de datos.

### Pasos a seguir ###

Vamos a probar el lanzamiento de una release usando el flujo de
trabajo GitFlow.

1. Cread un _issue_ con la tarea _Lanzar release 1.3.0_.

2. Siguiendo las indicaciones de GitFlow, crear la rama local
   `release-1.3.0` a partir de `develop`.
   
3. En esta rama se deben realizar los cambios espec铆ficos de la
   versi贸n. En nuestro caso:
   
    - Cambiar en la p谩gina `Acerca de` "Versi贸n 1.3.0-SNAPSHOT" a
          "Versi贸n 1.3.0" y a帽adir la fecha de publicaci贸n.
    - Cambiar el fichero `pom.xml`.
    - Generad el **esquema de datos** de la base de datos postgres
      y guardarlo en `sql/schema-1.3.0.sql`. 
    - Comparar este esquema con el esquema anterior y crear el script
      de migraci贸n con las instrucciones `ALTER TABLE` necesarias para
      actualizar la base de datos de producci贸n de la versi贸n 1.2.0 a
      la 1.3.0. Guardar el script en `sql/schema-1.2.0-1.3.0.sql`.
    
4. Publicad la rama `release-1.3.0` en GitHub y hacer un pull
   request sobre `main`. Una vez mezclado el PR a帽adir la
   etiqueta con la nueva versi贸n `1.3.0` en `main` creando la
   p谩gina de release en GitHub.

5.  Mezclar tambi茅n la rama de release con `develop` (se puede hacer
    tambi茅n con un PR).

6. Subir la nueva versi贸n de la imagen de docker a Docker Hub.

7. Una vez hecho esto ya se puede borrar la rama `release-1.3.0` y las
  ramas `main` y `develop` estar谩n actualizadas a la nueva
  versi贸n. Hacer por 煤ltimo un commit en `develop` (no hace falta PR)
  cambiando la versi贸n a `1.4.0-SNAPSHOT`.

8. Debemos comprobar que GitHub Actions pasa correctamente todos los
   tests de las nuevas caracter铆sticas que se a帽aden.


## 8. Despliegue de la nueva versi贸n y actualizaci贸n de la BD de producci贸n  ##

Deber茅is desplegar la nueva versi贸n de la aplicaci贸n en el servidor de
la asignatura, actualizando la base de datos de producci贸n con los
cambios introducidos.

### Pasos a seguir ###

1. Conectarse al servidor de la asignatura.
2. Descargar la nueva versi贸n de la aplicaci贸n.
3. Hacer una copia de seguridad de la base de datos, tal y como se
   explica en el apartado _Mantenimiento de la base de datos de
   producci贸n_. Dejar el fichero de copia de seguridad en el
   directorio ra铆z del usuario `alu` con el que se est谩 conectado al
   servidor de la asignatura.
4. Hacer una migraci贸n de la base de datos tal y como se explica en el
   mismo apartado anterior.
5. Lanzar el contenedor de la aplicaci贸n con el perfil `postgres-prod`
   y comprobar que funciona correctamente la aplicaci贸n en producci贸n.

<!--

## 9. Nuevas funcionalidades para la aplicaci贸n  ##

Cambiamos totalmente de asunto. Tenemos ahora que dejar de pensar como
desarrolladores y pensar como **responsables del producto**. Tenemos
que pensar en las pr贸ximas funcionalidades a implementar en la
aplicaci贸n. Las desarrollaremos en las 3 semanas que durar谩 la
pr谩ctica 4.

Deber茅is reuniros y pensar en c贸mo hacer el producto m谩s interesante
para los usuarios. Pensad que quer茅is poner la aplicaci贸n en
producci贸n y que est谩is buscando funcionalidades que la hagan
interesante para que los usuarios se suscriban a ella.

Ten茅is que poneros **en el lugar de los usuarios** y pensar en
funcionalidades que les puedan ser 煤tiles, resolver alg煤n problema. No
es cuesti贸n de a帽adir funcionalidades porque s铆, sino que ten茅is que
intentar hacer en 3 semanas un producto lo m谩s coherente y 煤til
posible. 

Si os qued谩is sin ideas, pod茅is mirar la aplicaci贸n
[todoist](https://todoist.com/features). Se trata de una aplicaci贸n
completa de gesti贸n de tareas pendientes similar a la que estamos
desarrollando (aunque ellos tienen muchos m谩s desarrolladores y
presupuesto que nosotros ).

El resultado ser谩 un tablero Trello con columnas denominadas _Backlog
(1)_ y _Backlog (2)_: en la que se encuentren las descripciones de las
funcionalidades candidatas a implementarse en la siguiente pr谩ctica,
ordenadas de m谩s interesante a menos (de arriba a abajo y de izquierda
a derecha) y etiquetadas con su tama帽o. La imagen de abajo es un
ejemplo, con los t铆tulos de la mayor铆a de las funcionalidades borradas
para no dar demasiadas ideas.

<img src="imagenes/tablero.png" width="700px"/>

En la primera semana de la pr谩ctica 5 el profesor se reunir谩 con el
equipo y podr谩 pediros alguna aclaraci贸n sobre las propuestas y la
estimaci贸n de tama帽o de las funcionalidades antes de validarlas.

### Pasos a seguir ###

- Haced una reuni贸n, generar ideas en un _brainstorming_, organizarlas
  y estimar su dificultad. S贸lo podr茅is definir funcionalidades de
  tama帽o de uno y dos puntos. Si alguna funcionalidad es mayor,
  deber茅is descomponerla en otras m谩s peque帽as.

    Los puntos indican un tama帽o relativo. Si estim谩is una historia de
    usuario en 2 puntos es porque pens谩is que tardar茅is el doble en
    terminarla que otra de 1 punto.

    Para estimar la dificultad pod茅is usar _planning pocker_: se
    explica la funcionalidad y cada miembro del equipo elige un
    n煤mero: 1, 2, m谩s de 2. Se ense帽an simult谩neamente y se explican
    las diferencias. Se siguen haciendo rondas hasta que hay un
    consenso.
          
- Deb茅is seleccionar historias que sumen entre 12 y 15 puntos para
  implementar en la siguiente pr谩ctica 5. Para los equipos de 2
  personas seleccionar entre 8 y 10 puntos. La pr谩ctica 4 tendr谩 una
  duraci贸n de 3 semanas.
  
    Seleccionar las historias que pens茅is que hacen un producto
    atractivo, coherente y 煤til para el usuario. Ordenar las historias
    seg煤n su valor. Para estimar el valor pod茅is hacer algo similar al
    _planning pocker_ pero usando los n煤meros 1, 2 y 3 como forma de
    identificar la utilidad o valor de cada historia.

- Cread un tablero Trello compartido e invitad al profesor
  (`domingo.gallardo@ua.es`). Cread las etiquetas `1` y `2` con
  distintos colores que indican el tama帽o de cada funcionalidad.

- A帽adir historias de usuario, ordenadas de mayor a menor importancia
  (arriba a la izquierda la m谩s importante y abajo a la derecha la
  menos). Cada tarjeta de Trello debe contener:

    - **T铆tulo**. Aparece en la tarjeta.
    - **Descripci贸n**. Muy breve, al estilo de las historias de
      XP. Pod茅is usar el est谩ndar "Como XXX quiero XXX para XXX", o
      cualquier otro estilo. Pero siempre debe quedar claro que la
      caracter铆stica debe ser una nueva funcionalidad que pueda usar o
      que note un usuario de la aplicaci贸n.
    - **Borrador de la interfaz de usuario**. Puede ser un dibujo
      hecho a mano o un mockup hecho con alguna aplicaci贸n. No hace
      falta mucho detalle, s贸lo para que el cliente (el profesor)
      entienda la historia.
    - **Condiciones de satisfacci贸n**: condiciones que deben cumplirse
      para considerar que la historia est谩 terminada. Son
      fundamentales a la hora de definir pruebas autom谩ticas y
      manuales. Las pruebas se definen a partir de estas condiciones
      de satisfacci贸n.
  
En la primera semana de la pr谩ctica 5 el profesor se reunir谩 con el
equipo y podr谩 pediros alguna aclaraci贸n sobre las propuestas y la
estimaci贸n de tama帽o de las funcionalidades antes de validarlas.


-->

<!--


## Despliegue en producci贸n con Docker ##


Este apartado lo realizar谩 el **responsable de integraci贸n continua**,
pero todos los miembros del equipo deben conocer y entender todos los
pasos.


### Sobreescribir propiedades desde la l铆nea de comando ###

Hemos visto que al lanzar la aplicaci贸n Spring Boot podemos
seleccionar el perfil activo. Por ejemplo para lanzar la aplicaci贸n
usando como perfil activo el fichero `application-mysql.properties`:

```
mvn spring-boot:run -Dspring.profiles.active=mysql
```

Tambi茅n hemos visto que podemos seleccionar este perfile para lanzar los tests:

```
mvn test -Dspring.profiles.active=mysql
```

La opci贸n `-D` permite sobreescribir una propiedad del fichero de
propiedades. Por ejemplo, podemos lanzar la aplicaci贸n modificando el
usuario y la contrase帽a de una conexi贸n a una base de datos con el
siguiente comando:

```
mvn spring-boot:run -Dspring.datasource.username=root -Dspring.datasource.password=12345678
```

Tambi茅n es posible definir variables en el propio fichero de
propiedades para proporcionar nombres m谩s cortos o reutilizar un mismo
valor en varias propiedades.

Por ejemplo, en el siguiente fichero `application.properties`
definimos el [nivel de
logging](https://stackoverflow.com/a/37167120/540801) (que puede ser
`off`, `fatal`, `error`, `warn`, `info`, `debug`, `trace`, `all`) y
usamos el mismo nivel para los distintos paquetes de la aplicaci贸n:

```
logging=info
logging.level.org.springframework=${logging}
logging.level.root=${logging}
logging.level.org.hibernate=${logging}
logging.level.sql=${logging}
```

Podr铆amos entonces modificar el nivel de logs modificando la variable
`logging` al lanzar los tests de la aplicaci贸n, para que s贸lo muestre
los mensajes de error:

```
mvn test -Dloggin=error
```

En la aplicaci贸n vamos a usar esta variable y tambi茅n otras que nos
van a permitir configurar las propiedades relacionadas con la conexi贸n
con la base de datos.

### Pasos a seguir ###

- Abre un _issue_ denominado `Dockerizaci贸n de la aplicaci贸n` en el
  que vas a configurar la aplicaci贸n para lanzarla con
  `docker-compose`. Como siempre, desarrolla el _issue_ en una rama
  propia.

- Modifica los ficheros de propiedades de ejecuci贸n para que queden de
  la siguiente forma:

    **Fichero `src/main/resources/application.properties`**

        spring.datasource.url=jdbc:h2:mem:dev
        spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.H2Dialect
        spring.jpa.hibernate.ddl-auto=update
        spring.datasource.data=classpath:datos-dev.sql
        spring.datasource.initialization-mode=always
        spring.h2.console.enabled=true
        spring.h2.console.path=/h2-console


        logging=info
        logging.level.org.springframework=${logging}
        logging.level.root=${logging}
        logging.level.org.hibernate=${logging}
        logging.level.sql=${logging}

    **Fichero `src/main/resources/application-mysql.properties`**

        db_ip=localhost:3306
        db_user=root
        db_passwd=
        spring.datasource.url=jdbc:mysql://${db_ip}/mads
        spring.datasource.username=${db_user}
        spring.datasource.password=${db_passwd}
        spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.MySQL5InnoDBDialect
        spring.jpa.hibernate.ddl-auto=update
        spring.datasource.initialization-mode=never

- Probamos que funcionan bien las variables de
  configuraci贸n. Para ello, lanzamos mysql en un puerto distinto, el 3316:
  
        docker run -d -p 3316:3306 --name mysql-otro-puerto -e MYSQL_ALLOW_EMPTY_PASSWORD=yes -e MYSQL_DATABASE=mads mysql:5 
  
    y probamos a lanzar la aplicaci贸n modificando la variable `db_ip`
    para que se conecte a ese nuevo puerto:
  
        mvn spring-boot:run -Dspring.profiles.active=mysql -Ddb_ip=localhost:3316

    La aplicaci贸n debe arrancar correctamente, conect谩ndose a la base
    de datos en el nuevo puerto.

    Por 煤ltimo, borramos el contenendor de prueba creado:
    
         docker container stop mysql-otro-puerto
         docker container rm mysql-otro-puerto

- Realiza un commit con los nuevos ficheros de propiedades.

!!! Note "Nota"
    Es posible utilizar la variable `db_ip` para facilitar la conexi贸n
    de la aplicaci贸n a un contenedor Docker de MySQL lanzado en
    Windows con _Docker Toolbox_. En este caso hay que especificar la
    direcci贸n IP en la que se est谩 ejecutando el contenedor Docker.


### Imagen Docker de la aplicaci贸n ###

Hemos visto [en teor铆a](https://github.com/domingogallardo/apuntes-mads/blob/master/sesiones/08-integracion-entrega-continua/integracion-entrega-continua.md#demostraci贸n-de-docker) c贸mo crear im谩genes Docker. Vamos a crear una
imagen con nuestra aplicaci贸n `mads-todolist`.

El fichero `Dockerfile` es el responsable de construir la m谩quina
Docker. Usaremos el siguiente `Dockerfile`:

```
#### Stage 1: Build the application
FROM openjdk:8-jdk-alpine as build
    
# Set the current working directory inside the image
WORKDIR /app

# Copy maven executable to the image
COPY mvnw .
COPY .mvn .mvn

# Copy the pom.xml file
COPY pom.xml .

# Build all the dependencies in preparation to go offline.
# This is a separate step so the dependencies will be cached unless
# the pom.xml file has changed.
RUN ./mvnw dependency:go-offline -B

# Copy the project source
COPY src src

# Package the application
RUN ./mvnw package -DskipTests
RUN mkdir -p target/dependency && (cd target/dependency; jar -xf ../*.jar)

#### Stage 2: A minimal docker image with command to run the app
FROM openjdk:8-jre-alpine

# Copy project dependencies from the build stage
COPY --from=build /app/target/dependency/BOOT-INF/lib /app/lib
COPY --from=build /app/target/dependency/META-INF /app/META-INF
COPY --from=build /app/target/dependency/BOOT-INF/classes /app

# Define environment variables
ENV PROFILE=
ENV DB_IP=
ENV DB_USER=
ENV DB_PASSWD=
ENV LOGGING=

CMD java -Dspring.profiles.active=$PROFILE -Ddb_ip=$DB_IP -Ddb_user=$DB_USER \
    -Ddb_passwd=$DB_PASSWD -Dlogging=$LOGGING -cp app:app/lib/* madstodolist.Application
```


Se trata de un fichero que construye la imagen docker en dos fases. En
una primera fase compila la aplicaci贸n y guarda todos los `jars` en el
directorio `target`. En la segunda fase crea la m谩quina resultante, basada en
`openjdk:8-jre-alpine`, con las librer铆as compiladas previamente.

Docker permite definir variables de entorno que pueden ser modificadas
al lanzar la m谩quina. Definimos las mismas variables que hemos
definido en el fichero de propiedades de spring boot:

- `PROFILE`: perfil a usar al lanzar la aplicaci贸n.
- `DB_IP`: direcci贸n IP y puerto de la base de datos con la que se
  debe conectar la aplicaci贸n.
- `DB_USER`: usuario de la base de datos con el que la aplicaci贸n se
  conecta con la base de datos.
- `DB_PASSWD`: contrase帽a del usuario de la base de datos.
- `LOGGING`: nivel de logging que va a realizar la aplicaci贸n.

Para lanzar una imagen docker definiendo un valor de una variable de
entorno hay que utilizar el flag `-e VARIABLE=valor`. 


### Pasos a seguir ###

- Crea una cuenta en [DockerHub](https://hub.docker.com). En esta
  cuenta se publicar谩 la imagen docker de la aplicaci贸n.

- Crea el fichero `Dockerfile` anterior en el directorio principal de
  la aplicaci贸n.
  
- Construye la m谩quina docker. Utiliza como _usuario_ el usuario que
  has creado en DockerHub.

        docker build -t USUARIO/mads-todolist-equipo-XX .

    Prueba a ejecutar la aplicaci贸n trabajando con la base de datos en
    memoria y con logs de nivel `INFO`:
    
        docker run --rm -it -p 8080:8080 -e LOGGING=error USUARIO/mads-todolist-equipo-XX

    El flag `-it` permite visualizar en el terminal de forma
    interactiva la salida est谩ndar de la aplicaci贸n Play y terminarla
    haciendo un `CTRL-C`.

    Y prueba por 煤ltimo a ejecutar la aplicaci贸n funcionando con la imagen docker
    con la base de datos MySQL:

        $ docker run -d -p 3306:3306 --name mysql-develop -e MYSQL_ALLOW_EMPTY_PASSWORD=yes -e MYSQL_DATABASE=mads mysql:5 
        $ docker run --rm -it --link mysql-develop -p 8080:8080 \
          -e PROFILE=mysql -e DB_IP=mysql-develop:3306 -e DB_USER=root -e LOGGING=info \
          USUARIO/mads-todolist-equipo-XX


- Cuando compruebes que todo funciona correctamente, sube a _docker hub_
  la imagen compilada:
  
        $ docker login
        # introduce tus credenciales en docker hub
        $ docker push USUARIO/mads-todolist-equipo-XX
      
- Comprueba en _docker hub_ que la imagen se ha subido
  correctamente. Uno de los compa帽eros debe probar que la imagen
  funciona correctamente, ejecutando las dos instrucciones
  anteriores en su m谩quina:

        $ docker run -d -p 3306:3306 --name mysql-develop -e MYSQL_ALLOW_EMPTY_PASSWORD=yes -e MYSQL_DATABASE=mads mysql:5 
        $ docker run --rm -it --link mysql-develop -p 8080:8080 \
          -e PROFILE=mysql -e DB_IP=mysql-develop:3306 -e DB_USER=root -e LOGGING=info \
          USUARIO/mads-todolist-equipo-XX
  
    Comprobad que se descarga correctamente la m谩quina
    `USUARIO/mads-todolist-equipo-XX` y que la aplicaci贸n se lanza sin
    errores.

- Por 煤ltimo, modifica el script de Travis para que sea Travis quien
  construya y publique la m谩quina docker. Antes de que se ejecute el
  script deber谩s configurar en los ajustes del repositorio en Travis
  (_travis-ci.com > USUARIO/mads-todolist-equipo-XX > Settings >
  Environment Variables_) las variables: `DOCKER_USERNAME` y
  `DOCKER_PASSWORD`, para que Travis pueda publicar en tu cuenta de
  DockerHub.
  
    <img src="imagenes/variables-entorno-travis.png" width="700px"/>
  
    L铆neas a a帽adir al final del fichero `.travis.yml`:
    
        after_success:
          - docker build -t USUARIO/mads-todolist-equipo-XX:$TRAVIS_BUILD_NUMBER .
          - if [ "$TRAVIS_EVENT_TYPE" != "pull_request" ]; then
            docker login -u="$DOCKER_USERNAME" -p="$DOCKER_PASSWORD";
            docker push USUARIO/mads-todolist-equipo-XX:$TRAVIS_BUILD_NUMBER;
            docker tag USUARIO/mads-todolist-equipo-XX:$TRAVIS_BUILD_NUMBER USUARIO/mads-todolist-equipo-XX:latest;
            docker push USUARIO/mads-todolist-equipo-XX:latest;
            fi

    F铆jate en el script `after_success`. Es lo que Travis har谩 despu茅s
    de ejecutar con 茅xito los tests:
    
    - Construir la m谩quina docker de nuestra aplicaci贸n, asign谩ndole
    como etiqueta el n煤mero de build actuar.
    - Si la ejecuci贸n de Travis es debida a un evento que no es un
    _pull request_ (o sea, cuando sea un build disparado por el commit
    de merge con la rama en la que se integra el PR) se logea en
    docker hub con el usuario y la contrase帽a definidas en las
    variables. Una vez logeado, publica la imagen usando como n煤mero
    de _tag_ el n煤mero de build. Y esta 煤ltima imagen tambi茅n se
    vuelve a etiquetar como `latest` y se vuelve a subir.
  
    Por ejemplo, cuando se realice el build `#28` se publicar谩 la
    imagen resultante de este build con las etiquetas `28` y `latest`:
    `USUARIO/mads-todolist-equipo-XX:28` y
    `USUARIO/mads-todolist-equipo-XX:latest`.


- Por 煤ltimo, a帽ade el siguiente fichero `docker-compose.yml` en el
  directorio ra铆z de la aplicaci贸n. La aplicaci贸n `docker-compose`
  permite automatizar la puesta en funcionamiento y conexi贸n de m谩s de
  un contenedor docker. En nuestro caso, servir谩 para poner en marcha
  con un 煤nico comando el contenedor de base de datos y nuestra
  aplicaci贸n.

    Fichero `docker-compose.yml`:
        
        version: '3.7'

        # Define services
        services:

          # App backend service
          mads-todolist:
            image: USUARIO/mads-todolist-equipo-XX
            ports:
              - "8080:8080" # Forward the exposed port 8080 on the container to port 8080 on the host machine
            restart: always
            depends_on:
              - db # This service depends on mysql. Start that first.
            environment: # Pass environment variables to the service
              PROFILE: mysql
              DB_IP: db:3306
              DB_USER: root
              LOGGING: info
            networks: # Networks to join (Services on the same network can communicate with each other using their name)
              - backend

          # Database Service (Mysql)
          db:
            image: mysql:5
            ports:
              - "3306:3306"
            restart: always
            environment:
              MYSQL_DATABASE: mads
              MYSQL_ALLOW_EMPTY_PASSWORD: 'yes'
            volumes:
              - db-data:/var/lib/mysql
            networks:
              - backend

        # Volumes
        volumes:
          db-data:

        # Networks to be created to facilitate communication between containers
        networks:
          backend:
  
  - Prueba que funciona correctamente `docker-compose` ejecutando el
    comando `docker-compose up`. Para asegurarte de que la imagen que
    ejecutas es la que se descarga de docker hub debes borrar
    previamente la imagen que tengas en tu ordendador:
    
    ```
    $ docker container prune
    $ docker image rm USUARIO/mads-todolist-equipo-XX
    $ docker-compose up
    ```
    
    Ver谩s c贸mo se ponen en marcha el contenedor `mysql` y el
    contenedor con nuestra aplicaci贸n. Prueba a conectarte a la
    aplicaci贸n y comprobar que todo funciona correctamente.
    Puedes terminar la ejecuci贸n
    haciendo `CTRL-C` o lanzando desde otra terminal el comando
    
    ```
    docker-compose down
    ```

  - En el script de `docker-compose` el contenedor `mysql` utiliza un
    [volumen](https://docs.docker.com/storage/volumes/). Esto permite
    conservar los datos que se introduzcan en la ejecuci贸n del
    programa, aunque el contenedor se borre. Tambi茅n ser铆a posible
    hacer un backup de estos datos a partir del volumen.
    
    Para listar los vol煤menes mantenidos por docker:
    
    ```
    docker volume ls
    ```
    
    Para eliminar un volumen:
    
    ```
    docker volume rm nombre-volumen
    ```
    
    Y para elminar todos los vol煤menes:
    
    ```
    docker volume prune
    ```

- Haz un commit y sube los cambios a GitHub. 
- Crea el pull request que cierra el _issue_ y ci茅rralo, comprobando
  que Travis construye la m谩quina docker y la publica en docker hub.

    <img src="imagenes/imagenes-docker-hub.png" width="700px"/>

- Por 煤ltimo un compa帽ero debe probar el comando `docker-compose up` y
  comprobar si se ponen en marcha las im谩genes docker y nuestra
  aplicaci贸n funciona correctamente. 

-->


## 9. Documentaci贸n, entrega y evaluaci贸n ##

Deber茅is a帽adir una p谩gina de documentaci贸n `/doc/practica4.md` en la
que deber茅is incluir:

- Breve documentaci贸n t茅cnica de los cambios introducidos en la
  aplicaci贸n.
- Detalles del despliegue de producci贸n: usuario `alu` con el que se
  ha realizado la puesta en producci贸n, as铆 como directorio y fichero
  en el que se encuentra (en el servidor de la asignatura) el backup
  de la base de datos de producci贸n. Script de migraci贸n de la base de
  datos.
  

- La pr谩ctica tiene una duraci贸n de 2 semanas y debe estar terminada
  el martes 23 de noviembre.
- La calificaci贸n de la pr谩ctica tiene un peso de un 15% en la nota
  final de pr谩cticas.
- 
- Para realizar la entrega uno de los miembros del equipo debe subir a
  Moodle un ZIP que contenga todo el proyecto, incluyendo el
  directorio `.git` que contiene la historia Git. Para ello comprime
  tu directorio local del proyecto despu茅s de haber hecho un `mvn
  clean` para eliminar el directorio `target` que contiene los
  binarios compilados.

Para la evaluaci贸n se tendr谩 en cuenta:

- Desarrollo continuo (los _commits_ deben realizarse a lo largo de
  las semanas y no dejar todo para la 煤ltima).
- Correcto desarrollo de la metodolog铆a.
- Dise帽o e implementaci贸n del c贸digo y de los tests de las
  caracter铆sticas desarrolladas.
- Documentaci贸n.

